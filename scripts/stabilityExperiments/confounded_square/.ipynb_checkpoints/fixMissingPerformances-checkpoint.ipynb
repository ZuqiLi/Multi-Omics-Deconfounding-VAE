{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bdc6e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e67c4a86",
   "metadata": {},
   "source": [
    "# advNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a01c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.utils.data as data\n",
    "import sys\n",
    "PATH = \"/trinity/home/skatz/PROJECTS/Multi-view-Deconfounding-VAE\"\n",
    "sys.path.append(PATH)\n",
    "from models.clustering import *\n",
    "from Data.preprocess import *\n",
    "from models.func import reconAcc_relativeError\n",
    "### Specify here which model you want to use: XVAE_adversarial_multiclass, XVAE_scGAN_multiclass, XVAE_adversarial_1batch_multiclass\n",
    "from models.adversarial_XVAE_multiclass import XVAE, advNet, XVAE_scGAN_multiclass \n",
    "\n",
    "\n",
    "def prep_data(seed):\n",
    "\n",
    "    ''' Set seeds for replicability  -Ensure that all operations are deterministic on GPU (if used) for reproducibility '''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    L.seed_everything(seed, workers=True)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    ''' Set PATHs '''\n",
    "    ## PATH_data = \"Data\"\n",
    "    ### For EMC cluster\n",
    "    PATH_data = \"/data/scratch/skatz/PROJECTS/multiview_VAE/data\"\n",
    "\n",
    "\n",
    "    ''' Load data '''\n",
    "    X1 = np.loadtxt(os.path.join(PATH_data, \"TCGA\",'TCGA_mRNA2_confounded.csv'), delimiter=\",\")\n",
    "    X2 = np.loadtxt(os.path.join(PATH_data, \"TCGA\",'TCGA_DNAm_confounded.csv'), delimiter=\",\")\n",
    "    X1 = torch.from_numpy(X1).to(torch.float32)\n",
    "    X2 = torch.from_numpy(X2).to(torch.float32)\n",
    "    traits = np.loadtxt(os.path.join(PATH_data, \"TCGA\",'TCGA_clinic2.csv'), delimiter=\",\", skiprows=1, usecols=(1,2,3,4,5))\n",
    "    Y = traits[:, -1]\n",
    "    '''\n",
    "    # The rest as confounders\n",
    "    conf = traits[:, :-1] # stage, age, race, gender\n",
    "    age = conf[:,1].copy()\n",
    "    # rescale age to [0,1)\n",
    "    age = (age - np.min(age)) / (np.max(age) - np.min(age) + 1e-8)\n",
    "    # bin age accoring to quantiles\n",
    "    #n_bins = 10\n",
    "    #bins = np.histogram(age, bins=10, range=(age.min(), age.max()+1e-8))[1]\n",
    "    #age = np.digitize(age, bins) # starting from 1\n",
    "    conf[:,1] = age\n",
    "    # onehot encoding\n",
    "    conf_onehot = OneHotEncoder(sparse=False).fit_transform(conf[:,:3])\n",
    "    conf = np.concatenate((conf[:,[3]], conf_onehot), axis=1)\n",
    "    # select only gender\n",
    "    conf = conf[:,[0]]\n",
    "    '''\n",
    "    # load artificial confounder\n",
    "    conf_type = 'continuous'\n",
    "    conf = np.loadtxt(os.path.join(PATH_data, \"TCGA\",'TCGA_confounder.csv'))[:,None]\n",
    "    conf = torch.from_numpy(conf).to(torch.float32)             ### Watch out: continous variables should go first\n",
    "    if conf_type == 'categ':\n",
    "        conf = torch.nn.functional.one_hot(conf[:,0].to(torch.int64))\n",
    "    print('Shape of confounders:', conf.shape)\n",
    "\n",
    "\n",
    "    ''' Split into training and validation sets '''\n",
    "    n_samples = X1.shape[0]\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    train_idx, val_idx = indices[:2000], indices[2000:]\n",
    "\n",
    "    X1_train, X1_val = scale(X1[train_idx,:]), scale(X1[val_idx,:])\n",
    "    X2_train, X2_val = scale(X2[train_idx,:]), scale(X2[val_idx,:])\n",
    "    conf_train, conf_val = conf[train_idx,:], conf[val_idx,:]\n",
    "\n",
    "    ''' Initialize Dataloader '''\n",
    "    train_loader = data.DataLoader(\n",
    "                        ConcatDataset(X1_train, X2_train, conf_train), \n",
    "                        batch_size=64, \n",
    "                        shuffle=True, \n",
    "                        drop_last=False, \n",
    "                        num_workers=5)\n",
    "    val_loader = data.DataLoader(\n",
    "                        ConcatDataset(X1_val, X2_val, conf_val), \n",
    "                        batch_size=64, \n",
    "                        shuffle=False, \n",
    "                        drop_last=False, \n",
    "                        num_workers=5)\n",
    "    return X1, X2, conf, Y\n",
    "\n",
    "    \n",
    "def do_assessment(X1, X2, conf, Y, PATH, modelname):\n",
    "    epochs_ae_w_advNet = 150\n",
    "    X1_test = scale(X1)\n",
    "    X2_test = scale(X2)\n",
    "    conf_test = conf\n",
    "    labels = ['Confounder']\n",
    "    conf_type=\"continuous\"\n",
    "    epochs_preTrg_ae = 5        #10\n",
    "    epochs_preTrg_advNet = 5    #10\n",
    "\n",
    "\n",
    "    RE_X1s, RE_X2s, RE_X1X2s = [], [], []\n",
    "    clusts = []\n",
    "    SSs, DBs = [], []\n",
    "    n_clust = len(np.unique(Y))\n",
    "    corr_diff = []\n",
    "\n",
    "    ## advNet performance for predicting the confounder\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    scores = np.zeros((50, conf_test.shape[1]))\n",
    "    for i in range(1):         \n",
    "        ckpt_path = f\"{PATH}/lightning_logs/{modelname}/XVAE_adversarialTrg/epoch{epochs_ae_w_advNet}/checkpoints\"\n",
    "        ckpt_file = f\"{ckpt_path}/{os.listdir(ckpt_path)[0]}\"\n",
    "        ckpt_xvae_path = f\"{PATH}/lightning_logs/{modelname}/pre_XVAE/epoch{epochs_preTrg_ae}/checkpoints\"\n",
    "        ckpt_xvae_file = f\"{ckpt_xvae_path}/{os.listdir(ckpt_xvae_path)[0]}\"\n",
    "        ckpt_advNet_path = f\"{PATH}/lightning_logs/{modelname}/pre_advNet/epoch{epochs_preTrg_advNet}/checkpoints\"\n",
    "        ckpt_advNet_file = f\"{ckpt_advNet_path}/{os.listdir(ckpt_advNet_path)[0]}\"\n",
    "\n",
    "        model = XVAE_scGAN_multiclass.load_from_checkpoint(ckpt_file,\n",
    "                PATH_xvae_ckpt=ckpt_xvae_file, PATH_advNet_ckpt=ckpt_advNet_file, \n",
    "                map_location=torch.device(\"cpu\"))\n",
    "\n",
    "        # Loop over dataset and test on batches\n",
    "        indices = np.array_split(np.arange(X1_test.shape[0]), 20)\n",
    "        y_pred_all, y_true_all = [], []\n",
    "        for idx in indices:\n",
    "            y_pred, _ = model.advNet_pre.forward(X1_test[idx], X2_test[idx])\n",
    "            y_pred = [y_pred[j].detach().numpy() for j in range(y_pred.shape[0])]\n",
    "            y_pred_all.append(y_pred)\n",
    "\n",
    "        y_pred_all = np.concatenate(y_pred_all)\n",
    "\n",
    "        for j in range(conf_test.shape[1]):\n",
    "            scores[i,j] = roc_auc_score(conf_test[:,j], y_pred_all[:,j])\n",
    "\n",
    "    scores = np.mean(scores, 0)\n",
    "    for i in range(conf_test.shape[1]):\n",
    "        print(f\"Conf{i+1}\", \"\\t\", round(scores[i], 2))\n",
    "\n",
    "    ## Compute reconstruction and clustering metrics\n",
    "    # Sample multiple times from the latent distribution for stability\n",
    "    for i in range(1):         ## 50\n",
    "        corr_res = []\n",
    "        for epoch in [1, epochs_ae_w_advNet]:\n",
    "            ckpt_path = f\"{PATH}/lightning_logs/{modelname}/XVAE_adversarialTrg/epoch{epoch}/checkpoints\"\n",
    "            ckpt_file = f\"{ckpt_path}/{os.listdir(ckpt_path)[0]}\"\n",
    "            ckpt_xvae_path = f\"{PATH}/lightning_logs/{modelname}/pre_XVAE/epoch{epochs_preTrg_ae}/checkpoints\"\n",
    "            ckpt_xvae_file = f\"{ckpt_xvae_path}/{os.listdir(ckpt_xvae_path)[0]}\"\n",
    "            ckpt_advNet_path = f\"{PATH}/lightning_logs/{modelname}/pre_advNet/epoch{epochs_preTrg_advNet}/checkpoints\"\n",
    "            ckpt_advNet_file = f\"{ckpt_advNet_path}/{os.listdir(ckpt_advNet_path)[0]}\"\n",
    "\n",
    "            model = XVAE_scGAN_multiclass.load_from_checkpoint(ckpt_file,\n",
    "                    PATH_xvae_ckpt=ckpt_xvae_file, PATH_advNet_ckpt=ckpt_advNet_file, map_location=torch.device(\"cpu\"))   #### addition so it works with CUDS as well\n",
    "\n",
    "            # Loop over dataset and test on batches\n",
    "            indices = np.array_split(np.arange(X1_test.shape[0]), 20)\n",
    "            z = []\n",
    "            X1_hat, X2_hat = [], []\n",
    "            for idx in indices:\n",
    "                z_batch = model.xvae.generate_embedding(X1_test[idx], X2_test[idx])\n",
    "                z.append(z_batch.detach().numpy())\n",
    "                X1_hat_batch, X2_hat_batch = model.xvae.decode(z_batch)\n",
    "                X1_hat.append(X1_hat_batch.detach().numpy())\n",
    "                X2_hat.append(X2_hat_batch.detach().numpy())\n",
    "\n",
    "            z = np.concatenate(z)\n",
    "            X1_hat = np.concatenate(X1_hat)\n",
    "            X2_hat = np.concatenate(X2_hat)\n",
    "\n",
    "            if epoch == epochs_ae_w_advNet:\n",
    "                # Compute relative error from the last epoch\n",
    "                RE_X1, RE_X2, RE_X1X2 = reconAcc_relativeError(X1_test, X1_hat, X2_test, X2_hat)\n",
    "                RE_X1s.append(RE_X1)\n",
    "                RE_X2s.append(RE_X2)\n",
    "                RE_X1X2s.append(RE_X1X2)\n",
    "                # Clustering the latent vectors from the last epoch\n",
    "                clust = kmeans(z, n_clust)\n",
    "                clusts.append(clust)\n",
    "                # Compute clustering metrics\n",
    "                SS, DB = internal_metrics(z, clust)\n",
    "                SSs.append(SS)\n",
    "                DBs.append(DB)\n",
    "\n",
    "            # Correlation between latent vectors and the confounder\n",
    "            corr_conf = [np.abs(np.corrcoef(z.T, conf[:,i])[:-1,-1]) for i in range(conf.shape[1])]\n",
    "            if conf_type == 'categ':\n",
    "                corr_conf = [np.mean(corr_conf)]\n",
    "            corr_res.append(pd.DataFrame(corr_conf, index=labels))\n",
    "        # Calculate correlation difference\n",
    "        # (corr_first_epoch - corr_last_epoch) / corr_first_epoch\n",
    "        corr_diff.append(list(((corr_res[0].T - corr_res[1].T).mean() / corr_res[0].T.mean())*100))\n",
    "\n",
    "    # Average relative errors over all samplings\n",
    "    print(\"Relative error (X1):\", np.mean(RE_X1s))\n",
    "    print(\"Relative error (X2):\", np.mean(RE_X2s))\n",
    "    print(\"Relative error (X1X2):\", np.mean(RE_X1X2s))\n",
    "\n",
    "    # Average correlation differences over all samplings\n",
    "    corr_diff_unpacked = list(zip(*corr_diff))\n",
    "    corr_dict = dict()\n",
    "    for i, label in enumerate(labels):\n",
    "        corr_dict[label] = np.array(corr_diff_unpacked[i]).mean()\n",
    "    print(\"Corr diff:\", corr_dict)\n",
    "\n",
    "    # Average clustering metrics over all samplings\n",
    "    print(\"Silhouette score:\", np.mean(SSs))\n",
    "    print(\"DB index:\", np.mean(DBs))\n",
    "    # Compute consensus clustering from all samplings\n",
    "    con_clust, _, disp = consensus_clustering(clusts, n_clust)\n",
    "    print(\"Dispersion for co-occurrence matrix:\", disp)\n",
    "    ARI, NMI = external_metrics(con_clust, Y)\n",
    "    print(\"ARI for cancer types:\", ARI)\n",
    "    print(\"NMI for cancer types:\", NMI)\n",
    "    if conf_type == 'categ':\n",
    "        conf = np.argmax(conf, 1)\n",
    "    else:\n",
    "        conf = conf[:,0]\n",
    "    ARI_conf, NMI_conf = external_metrics(con_clust, conf)\n",
    "    print(\"ARI for confounder:\", ARI_conf)\n",
    "    print(\"NMI for confounder:\", NMI_conf)\n",
    "\n",
    "\n",
    "    ### Save\n",
    "    res = {'RelErr_X1':[np.mean(RE_X1s)],\n",
    "        'RelErr_X2':[np.mean(RE_X2s)],\n",
    "        'RelErr_X1X2':[np.mean(RE_X1X2s)],\n",
    "        'deconfounding_corrcoef':[list(corr_dict.values())],\n",
    "        'CC_dispersion':[disp],\n",
    "        'ss':[np.mean(SSs)],\n",
    "        'db':[np.mean(DBs)],\n",
    "        'ari_trueCluster':[ARI],\n",
    "        'nmi_trueCluster':[NMI],\n",
    "        'ari_confoundedCluster':[ARI_conf],\n",
    "        'nmi_confoundedCluster':[NMI_conf]\n",
    "        }    \n",
    "    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef29269a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77227,\n",
       " 41243,\n",
       " 49605,\n",
       " 72366,\n",
       " 35970,\n",
       " 76359,\n",
       " 82190,\n",
       " 29091,\n",
       " 12582,\n",
       " 11190,\n",
       " 26481,\n",
       " 898,\n",
       " 67697,\n",
       " 5077,\n",
       " 40893,\n",
       " 73328,\n",
       " 1234,\n",
       " 36831,\n",
       " 40468,\n",
       " 32112,\n",
       " 91832,\n",
       " 63030,\n",
       " 66183,\n",
       " 88487,\n",
       " 18647,\n",
       " 24327,\n",
       " 98104,\n",
       " 83611,\n",
       " 8950,\n",
       " 45800,\n",
       " 64890,\n",
       " 5535,\n",
       " 46159,\n",
       " 20759,\n",
       " 92757,\n",
       " 4207,\n",
       " 27273,\n",
       " 55781,\n",
       " 59957,\n",
       " 55094,\n",
       " 65036,\n",
       " 93891,\n",
       " 29583,\n",
       " 45871,\n",
       " 7557,\n",
       " 29839,\n",
       " 56731,\n",
       " 11192,\n",
       " 59,\n",
       " 90727,\n",
       " 34661]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runsAll = [int(ele.split(\"_\")[1]) for ele in os.listdir(f\"{PATH}/lightning_logs/confounded_square/stability/XVAE_scGAN_multiclass\")]\n",
    "runsAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256c1169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 77227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of confounders: torch.Size([2547, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m X1, X2, conf, Y \u001b[38;5;241m=\u001b[39m prep_data(seed)\n\u001b[1;32m      6\u001b[0m conf \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 7\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdo_assessment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#pd.DataFrame(res).to_csv(f\"{PATH}/lightning_logs/{modelname}/epoch150/results_performance.csv\", index=False)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 120\u001b[0m, in \u001b[0;36mdo_assessment\u001b[0;34m(X1, X2, conf, Y, PATH, modelname)\u001b[0m\n\u001b[1;32m    117\u001b[0m ckpt_advNet_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/lightning_logs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pre_advNet/epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs_preTrg_advNet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m ckpt_advNet_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_advNet_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlistdir(ckpt_advNet_path)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 120\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mXVAE_scGAN_multiclass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPATH_xvae_ckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_xvae_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH_advNet_ckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_advNet_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Loop over dataset and test on batches\u001b[39;00m\n\u001b[1;32m    125\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(np\u001b[38;5;241m.\u001b[39marange(X1_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1531\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1531\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:88\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 88\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:141\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec\u001b[38;5;241m.\u001b[39mvarkw:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     _cls_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 141\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# give model a chance to load something\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n",
      "File \u001b[0;32m~/PROJECTS/Multi-view-Deconfounding-VAE/models/adversarial_XVAE_multiclass.py:46\u001b[0m, in \u001b[0;36mXVAE_scGAN_multiclass.__init__\u001b[0;34m(self, PATH_xvae_ckpt, PATH_advNet_ckpt, labels_onehot, lamdba_deconf, distance, beta)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_step_outputs \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m### Load pre-trained XVAE model\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxvae \u001b[38;5;241m=\u001b[39m \u001b[43mXVAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_xvae_ckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoderOnly \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxvae\u001b[38;5;241m.\u001b[39menc_hidden_x1,\n\u001b[1;32m     48\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxvae\u001b[38;5;241m.\u001b[39menc_hidden_x2, \n\u001b[1;32m     49\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxvae\u001b[38;5;241m.\u001b[39menc_hidden_fused)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m### Load pre-trained advNet and freeze weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1531\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1531\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:60\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_checkpoint\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Union[Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m], Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningDataModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m     53\u001b[0m     checkpoint_path: Union[_PATH, IO],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningDataModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 60\u001b[0m         checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     64\u001b[0m         checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:51\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     49\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(path_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/pickle.py:1254\u001b[0m, in \u001b[0;36m_Unpickler.load_binpersid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_binpersid\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1253\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m-> 1254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/env_multiviewVAE/lib/python3.10/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "for seed in runsAll[:1]:\n",
    "    modelname = f'confounded_square/stability/XVAE_scGAN_multiclass/run_{seed}'\n",
    "\n",
    "    X1, X2, conf, Y = prep_data(seed)\n",
    "    conf = conf.detach().numpy()\n",
    "    res = do_assessment(X1, X2, conf, Y, PATH, modelname)\n",
    "    #pd.DataFrame(res).to_csv(f\"{PATH}/lightning_logs/{modelname}/epoch150/results_performance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_multiviewVAE)",
   "language": "python",
   "name": "env_multiviewvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
